{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee852f65-980d-45e3-acae-4ead88f8322f",
   "metadata": {},
   "source": [
    "# Predicting Customer Churn Using Machine Learning\n",
    "\n",
    "This project explores the use of machine learning models—Logistic Regression and Random Forest—to predict customer churn based on demographic and usage patterns. By developing and evaluating predictive models, we aim to understand key factors contributing to customer churn and compare the effectiveness of different algorithms.\n",
    "\n",
    "This analysis was completed as part of a **DataCamp project**, adapted and extended for personal skill development in **classification modeling, feature engineering, and model evaluation techniques** relevant to health-related predictive modeling.\n",
    "\n",
    "**Key Skills Applied:**\n",
    "- Data preprocessing and feature scaling\n",
    "- One-hot encoding of categorical variables\n",
    "- Classification modeling with Logistic Regression and Random Forest\n",
    "- Model evaluation using classification reports, confusion matrices, and accuracy metrics\n",
    "\n",
    "**Objective:** To develop a machine learning pipeline for predicting binary outcomes (churn vs. no churn), with workflows analogous to real-world health event prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fa11cb-cacd-474d-be4d-9ac36773a78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7d9e12-e1f3-4793-a895-53b927a7cd5f",
   "metadata": {},
   "source": [
    "## Data Loading and Merging\n",
    "We load two datasets containing customer demographic and usage information, and merge them to form a comprehensive dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278c331c-1aab-4989-94cf-c817b48bf43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "telecom_demographics = pd.read_csv('telecom_demographics.csv')  \n",
    "telecom_usage = pd.read_csv('telecom_usage.csv')  \n",
    "\n",
    "# Merge on 'customer_id'\n",
    "churn_df = pd.merge(telecom_demographics, telecom_usage, on='customer_id')\n",
    "\n",
    "# Churn proportion\n",
    "churn_proportion = churn_df['churn'].mean()  \n",
    "print(f\"Proportion of customers who have churned: {churn_proportion:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc6c489-faed-44cc-a150-a806122487d8",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Categorical variables are one-hot encoded, and numerical features are scaled for model readiness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa525ec-aa07-4f21-8308-2864d9e18727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_vars = churn_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# One-hot encode\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "encoded_vars = encoder.fit_transform(churn_df[categorical_vars])\n",
    "encoded_df = pd.DataFrame(encoded_vars, columns=encoder.get_feature_names_out(categorical_vars))\n",
    "\n",
    "# Merge encoded and drop originals\n",
    "churn_df = churn_df.drop(categorical_vars, axis=1)\n",
    "churn_df = pd.concat([churn_df, encoded_df], axis=1)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "target = churn_df['churn']\n",
    "features = churn_df.drop(['customer_id', 'churn'], axis=1)\n",
    "features_scaled = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcefd75-8d5b-4a5d-bedf-cb44cd7c883f",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "We split the data into training and testing sets to evaluate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdee0db-b669-4cbe-a0a9-3857a0a618ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3ae894-7b5e-4947-a2b2-ada38493e974",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "Two classification models are trained: Logistic Regression and Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbb64ac-eea5-4e55-97a4-fe26b923f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_pred = logreg.predict(X_test)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a632ca20-ea18-4c55-a232-486e9f8bd98f",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "We assess model performance using classification reports, confusion matrices, and accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e578dd23-1507-47bc-8494-7a6b4e4b36f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Evaluation\n",
    "print(\"Logistic Regression Report:\")\n",
    "print(classification_report(y_test, logreg_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, logreg_pred))\n",
    "\n",
    "# Random Forest Evaluation\n",
    "print(\"\\nRandom Forest Report:\")\n",
    "print(classification_report(y_test, rf_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, rf_pred))\n",
    "\n",
    "# Accuracy comparison\n",
    "logreg_accuracy = (logreg_pred == y_test).mean()\n",
    "rf_accuracy = (rf_pred == y_test).mean()\n",
    "\n",
    "print(f\"\\nLogistic Regression Accuracy: {logreg_accuracy:.4f}\")\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "\n",
    "higher_accuracy = \"Logistic Regression\" if logreg_accuracy > rf_accuracy else \"Random Forest\"\n",
    "print(\"Model with higher accuracy:\", higher_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bd0745-ca27-44c5-9a92-8312b0f66508",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Both models were able to predict customer churn with reasonable accuracy. The better-performing model was identified based on accuracy and classification metrics.\n",
    "\n",
    "**Next Steps:**  \n",
    "- Tune hyperparameters for improved performance.  \n",
    "- Evaluate model fairness across subgroups.  \n",
    "- Explore explainability tools for actionable insights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
